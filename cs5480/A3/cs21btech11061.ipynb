{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Assignment 3\n",
    "## Vishal Vijay Devadiga\n",
    "## CS21BTECH11061\n",
    "\n",
    "# Instructions\n",
    "\n",
    "- Answer all questions. We encourage best coding practices by not penalizing (i.e. you may not get full marks if you make it difficult for us to understand. Hence, use intuitive names for the variables, and comment your code liberally. You may use the text cells in the notebook for briefly explaining the objective of a code cell.)\n",
    "- It is expected that you work on these problems individually. If you have any doubts please contact the TA or the instructor no later than 2 days prior to the deadline.\n",
    "- You may use built-in implementations only for the basic functions such as sqrt, log, etc. from libraries such as numpy or PyTorch. Other high-level functionalities are expected to be implemented by the students. (Individual problem statements will make this clear. We can use the optimizers\n",
    "provided by the libraries such as PyTorch.)\n",
    "- For plots, you may use matplotlib and generate clear plots that are complete and easy to understand.\n",
    "- You are expected to submit the Python Notebooks saved as <your-roll-number>.ipynb\n",
    "- If you are asked to report your observations, use the mark down text cells in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3bb016e330>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All imports and global variables\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Self-Attention for Object Recognition with CNNs\n",
    "\n",
    "Implement a sample CNN with one or more self-attention layer(s) for performing object recognition over CIFAR-10 dataset. \n",
    "You have to implement the self-attention layer yourself and use it in the forward function defined by you. \n",
    "All other layers (fully connected, nonlinearity, conv layer, etc.) can be bulit-in implementations. \n",
    "The network can be a simpler one (e.g., it may have 1x Conv, 4x [Conv followed by SA], 1x Conv, and 1x GAP). \n",
    "Please refer to the reading material provided here or any other similar one. \n",
    "\n",
    "[10 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Object Recognition with Vision Transformer\n",
    "\n",
    "Implement and train an Encoder only Transformer (ViT-like) for the above object recognition task. \n",
    "In other words, implement multi-headed self-attention for the image classification (i.e., appending a <class>token to the image patches that are accepted as input tokens). \n",
    "Compare the performance of the two implementations (try to keep the number of parameters to be comparable and use the same amount of training and testing data). \n",
    "\n",
    "[10 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
