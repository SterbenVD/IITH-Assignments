{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":73111,"databundleVersionId":8040143,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# All imports and global variables\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom tqdm import tqdm\n\nimport numpy as np\nimport torch\nimport torchvision as tv\n\nfrom PIL import Image\nimport os\nimport math\n\n# Set random seed\nnp.random.seed(42)\ntorch.manual_seed(42)\nvalidation = False\n\n# Number of epochs\nnumber_of_epoch = 25\nimage_size = 128\nbatch_size = 32\nlearning_rate = 0.0005","metadata":{"execution":{"iopub.status.busy":"2024-04-28T14:24:23.999801Z","iopub.execute_input":"2024-04-28T14:24:24.000160Z","iopub.status.idle":"2024-04-28T14:24:30.235189Z","shell.execute_reply.started":"2024-04-28T14:24:24.000131Z","shell.execute_reply":"2024-04-28T14:24:30.234308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set device: GPU or CPU. Use GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-28T14:24:30.236872Z","iopub.execute_input":"2024-04-28T14:24:30.237444Z","iopub.status.idle":"2024-04-28T14:24:30.263212Z","shell.execute_reply.started":"2024-04-28T14:24:30.237417Z","shell.execute_reply":"2024-04-28T14:24:30.262307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# All images are to be resized to grayscale images\ntransform = transforms.Compose([\n    transforms.Resize((image_size, image_size)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.Grayscale(num_output_channels=1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5], std=[0.5])\n])\n\ntrain_dataset = tv.datasets.ImageFolder(root=\"/kaggle/input/iith-dl-contest-2024/train/train\", transform=transform)\nif validation:\n# Split the dataset into training and validation sets\n    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [int(0.8 * len(train_dataset)), len(train_dataset) - int(0.8 * len(train_dataset))])\n    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=8)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n\nclasses = train_dataset.classes\nprint(classes)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T14:24:30.264321Z","iopub.execute_input":"2024-04-28T14:24:30.264631Z","iopub.status.idle":"2024-04-28T14:24:47.243702Z","shell.execute_reply.started":"2024-04-28T14:24:30.264606Z","shell.execute_reply":"2024-04-28T14:24:47.242691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class fire(nn.Module):\n    def __init__(self, inplanes, squeeze_planes, expand_planes):\n        super(fire, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1, stride=1)\n        self.bn1 = nn.BatchNorm2d(squeeze_planes)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(squeeze_planes, expand_planes, kernel_size=1, stride=1)\n        self.bn2 = nn.BatchNorm2d(expand_planes)\n        self.conv3 = nn.Conv2d(squeeze_planes, expand_planes, kernel_size=3, stride=1, padding=1)\n        self.bn3 = nn.BatchNorm2d(expand_planes)\n        self.relu2 = nn.ReLU(inplace=True)\n\n        # using MSR initilization\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.in_channels\n                m.weight.data.normal_(0, math.sqrt(2./n))\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu1(x)\n        out1 = self.conv2(x)\n        out1 = self.bn2(out1)\n        out2 = self.conv3(x)\n        out2 = self.bn3(out2)\n        out = torch.cat([out1, out2], 1)\n        out = self.relu2(out)\n        return out\n\n\nclass SqueezeNet(nn.Module):\n    def __init__(self):\n        super(SqueezeNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 96, kernel_size=3, stride=1, padding=1) # 32\n        self.bn1 = nn.BatchNorm2d(96)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2) # 16\n        self.fire2 = fire(96, 16, 64)\n        self.fire3 = fire(128, 16, 64)\n        self.fire4 = fire(128, 32, 128)\n        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2) # 8\n        self.fire5 = fire(256, 32, 128)\n        self.fire6 = fire(256, 48, 192)\n        self.fire7 = fire(384, 48, 192)\n        self.fire8 = fire(384, 64, 256)\n        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2) # 4\n        self.fire9 = fire(512, 64, 256)\n        self.conv2 = nn.Conv2d(512, 10, kernel_size=1, stride=1)\n        self.avg_pool = nn.AvgPool2d(kernel_size=4, stride=4)\n        self.softmax = nn.LogSoftmax(dim=1)\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.in_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool1(x)\n        x = self.fire2(x)\n        x = self.fire3(x)\n        x = self.fire4(x)\n        x = self.maxpool2(x)\n        x = self.fire5(x)\n        x = self.fire6(x)\n        x = self.fire7(x)\n        x = self.fire8(x)\n        x = self.maxpool3(x)\n        x = self.fire9(x)\n        x = self.conv2(x)\n        x = self.avg_pool(x)\n        x = self.softmax(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-28T14:24:47.246890Z","iopub.execute_input":"2024-04-28T14:24:47.247357Z","iopub.status.idle":"2024-04-28T14:24:47.273894Z","shell.execute_reply.started":"2024-04-28T14:24:47.247313Z","shell.execute_reply":"2024-04-28T14:24:47.272613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, num_classes=50, input_size=128, in_channels=1):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, 3, 1, 1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.squeezenet = SqueezeNet()\n        self.gap = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(10, num_classes)\n    def forward(self, x):\n        x = self.pool(self.conv1(x))\n        x = self.squeezenet(x)\n        x = self.gap(x)\n        x = x.view(-1, 10)\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-28T14:24:47.275346Z","iopub.execute_input":"2024-04-28T14:24:47.275699Z","iopub.status.idle":"2024-04-28T14:24:47.288070Z","shell.execute_reply.started":"2024-04-28T14:24:47.275674Z","shell.execute_reply":"2024-04-28T14:24:47.287100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = Net(input_size=image_size, num_classes=len(classes), in_channels=1)\nnet = net.to(device)\nnet = net.train()\n\ncriterion = nn.CrossEntropyLoss().to(device)\noptimizer = optim.Adam(net.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T14:24:47.290058Z","iopub.execute_input":"2024-04-28T14:24:47.290338Z","iopub.status.idle":"2024-04-28T14:24:47.552403Z","shell.execute_reply.started":"2024-04-28T14:24:47.290315Z","shell.execute_reply":"2024-04-28T14:24:47.551363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the network\n\nfor epoch in range(number_of_epoch):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(tqdm(train_loader), 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data[0].to(device), data[1].to(device)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n        \n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        \n        optimizer.step()\n        \n        running_loss += loss.item()\n        if i % 100 == 99:\n            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n            running_loss = 0.0\n                \nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2024-04-28T14:24:47.553666Z","iopub.execute_input":"2024-04-28T14:24:47.554002Z","iopub.status.idle":"2024-04-28T14:24:47.559271Z","shell.execute_reply.started":"2024-04-28T14:24:47.553972Z","shell.execute_reply":"2024-04-28T14:24:47.558257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Test the network on the validation data\n\n# if validation:\n#     correct = 0\n#     total = 0\n#     net = net.eval()\n#     with torch.no_grad():\n#         for data in val_loader:\n#             images, labels = data[0].to(device), data[1].to(device)\n#             outputs = net(images)\n#             _, predicted = torch.max(outputs.data, 1)\n#             total += labels.size(0)\n#             correct += (predicted == labels).sum().item()\n    \n#     print('Accuracy of the network on the validation images: %d %%' % (100 * correct / total))","metadata":{"execution":{"iopub.status.busy":"2024-04-28T14:24:47.560466Z","iopub.execute_input":"2024-04-28T14:24:47.561152Z","iopub.status.idle":"2024-04-28T14:24:47.572615Z","shell.execute_reply.started":"2024-04-28T14:24:47.561119Z","shell.execute_reply":"2024-04-28T14:24:47.571663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find number of files in the test folder\nnumber_of_files = len(os.listdir(\"/kaggle/input/iith-dl-contest-2024/test/test\"))\nprint(number_of_files)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T14:24:47.573696Z","iopub.execute_input":"2024-04-28T14:24:47.574028Z","iopub.status.idle":"2024-04-28T14:24:48.055509Z","shell.execute_reply.started":"2024-04-28T14:24:47.573997Z","shell.execute_reply":"2024-04-28T14:24:48.054367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Actual test data is in the test/test folder, load it one by one and predict the class\n\npredicted_arr = []\n\ntf=transforms.Compose([\n    transforms.Resize((image_size,image_size)),\n    transforms.Grayscale(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5], std=[0.5])\n])\n\nnet = net.eval()\n\n# Load the test data using os.listdir\nfor id in tqdm(range(number_of_files)):\n    # Load the test data using tv\n    img = Image.open(f\"/kaggle/input/iith-dl-contest-2024/test/test/{id}.JPEG\")\n    img = tf(img)\n    \n    img = img.to(device)\n    \n    # Predict the class\n    output = net(img.unsqueeze(0))\n    _, predicted = torch.max(output.data, 1)\n    \n    predicted_arr.append(classes[predicted])","metadata":{"execution":{"iopub.status.busy":"2024-04-28T14:25:33.264536Z","iopub.execute_input":"2024-04-28T14:25:33.264954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct_csv = False\nwhile not correct_csv:\n    # Declare csv file\n    f = open(\"submission.csv\", \"w\")\n    f.write(\"ID,Category\\n\")\n    for id in range(number_of_files):\n        f.write(f\"{id}.JPEG,{predicted_arr[id]}\\n\")\n    f.close()\n    # Check if the csv file is correct\n    lines = len(open(\"submission.csv\", \"r\").readlines())\n    if lines == number_of_files + 1:\n        correct_csv = True","metadata":{"execution":{"iopub.status.busy":"2024-04-28T14:24:48.067800Z","iopub.status.idle":"2024-04-28T14:24:48.068175Z","shell.execute_reply.started":"2024-04-28T14:24:48.068007Z","shell.execute_reply":"2024-04-28T14:24:48.068022Z"},"trusted":true},"execution_count":null,"outputs":[]}]}