{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\BTECH 5th Sem\\FoML\\KaggleHackathon\\subsamples.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=108'>109</a>\u001b[0m random_forest_models \u001b[39m=\u001b[39m train_random_forest_models(subsamples)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m \u001b[39m# Example usage:\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m \u001b[39m# Replace 'your_test_data.csv', 'output_results.csv' with your actual file paths\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m predict_and_write_results_ensemble(random_forest_models, \u001b[39m'\u001b[39;49m\u001b[39mdata/iith_foml_2023_test.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39moutput_results.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32mc:\\BTECH 5th Sem\\FoML\\KaggleHackathon\\subsamples.ipynb Cell 1\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m X_test_imputed \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(imputer\u001b[39m.\u001b[39mtransform(test_data), columns\u001b[39m=\u001b[39mtest_data\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39m# Make predictions using the ensemble of models\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m final_predictions \u001b[39m=\u001b[39m ensemble_predict(models, X_test_imputed)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \u001b[39m# Create a DataFrame for results with ID and Predicted Category columns\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m results_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mID\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39marange(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(final_predictions) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m),  \u001b[39m# Assuming IDs start from 1\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mCategory\u001b[39m\u001b[39m'\u001b[39m: final_predictions\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m })\n",
      "\u001b[1;32mc:\\BTECH 5th Sem\\FoML\\KaggleHackathon\\subsamples.ipynb Cell 1\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(predictions, dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39m# Use voting to get the final prediction\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m final_predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mapply_along_axis(\u001b[39mlambda\u001b[39;49;00m x: np\u001b[39m.\u001b[39;49mbincount(x)\u001b[39m.\u001b[39;49margmax(), axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, arr\u001b[39m=\u001b[39;49mpredictions)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39mreturn\u001b[39;00m final_predictions\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Abhay Gupta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\shape_base.py:379\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[1;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    376\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    377\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mCannot apply_along_axis when any iteration dimensions are 0\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    378\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m--> 379\u001b[0m res \u001b[39m=\u001b[39m asanyarray(func1d(inarr_view[ind0], \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n\u001b[0;32m    381\u001b[0m \u001b[39m# build a buffer for storing evaluations of func1d.\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# remove the requested axis, and add the new ones on the end.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39m# laid out so that each write is contiguous.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39m# for a tuple index inds, buff[inds] = func1d(inarr_view[inds])\u001b[39;00m\n\u001b[0;32m    385\u001b[0m buff \u001b[39m=\u001b[39m zeros(inarr_view\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m res\u001b[39m.\u001b[39mshape, res\u001b[39m.\u001b[39mdtype)\n",
      "\u001b[1;32mc:\\BTECH 5th Sem\\FoML\\KaggleHackathon\\subsamples.ipynb Cell 1\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(predictions, dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39m# Use voting to get the final prediction\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m final_predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mapply_along_axis(\u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39;49mbincount(x)\u001b[39m.\u001b[39;49margmax(), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, arr\u001b[39m=\u001b[39mpredictions)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/BTECH%205th%20Sem/FoML/KaggleHackathon/subsamples.ipynb#W0sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39mreturn\u001b[39;00m final_predictions\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE,RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# CSV file\n",
    "file_path = 'data/iith_foml_2023_train.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming the target variable column is named \"Target Variable (Discrete)\"\n",
    "X = data.drop(columns=['Target Variable (Discrete)'])\n",
    "y = data['Target Variable (Discrete)']\n",
    "\n",
    "# Impute missing values using SimpleImputer\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Function to create sub-samples with specific class distribution\n",
    "def create_subsamples(X, y, num_samples_per_class=10):\n",
    "    subsamples = []\n",
    "    unique_classes = y.unique()\n",
    "\n",
    "    # Classes with a single-digit number of instances\n",
    "    single_digit_classes = y.value_counts()[y.value_counts() < 10].index.tolist()\n",
    "\n",
    "    # For each combination of 1, 0, 2, 6, 5, select num_samples_per_class instances without replacement\n",
    "    for class_combination in combinations([1, 0, 2, 6, 5], num_samples_per_class):\n",
    "        # Include classes with a single-digit number of instances\n",
    "        class_combination += tuple(single_digit_classes)\n",
    "\n",
    "        # Select instances for the sub-sample\n",
    "        sub_sample_indices = []\n",
    "        for cls in class_combination:\n",
    "            # If there are more instances than required, sample without replacement\n",
    "            if y[y == cls].shape[0] > num_samples_per_class:\n",
    "                sub_sample_indices.extend(y[y == cls].sample(num_samples_per_class, replace=False).index)\n",
    "            else:\n",
    "                sub_sample_indices.extend(y[y == cls].index)\n",
    "\n",
    "        subsamples.append((X.iloc[sub_sample_indices], y.iloc[sub_sample_indices]))\n",
    "\n",
    "    return subsamples\n",
    "\n",
    "# Function to train a random forest classifier on each sub-sample\n",
    "def train_random_forest_models(subsamples):\n",
    "    models = []\n",
    "\n",
    "    for X_sub, y_sub in subsamples:\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_sub, y_sub)\n",
    "        models.append(model)\n",
    "\n",
    "    return models\n",
    "\n",
    "# Function to make predictions using the ensemble of models\n",
    "def ensemble_predict(models, X):\n",
    "    predictions = []\n",
    "\n",
    "    for model in models:\n",
    "        prediction = model.predict(X)\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    # Convert predictions to integers\n",
    "    predictions = np.array(predictions, dtype=int)\n",
    "\n",
    "    # Use voting to get the final prediction\n",
    "    final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
    "\n",
    "    return final_predictions\n",
    "\n",
    "\n",
    "# Function to evaluate the ensemble on test data and write results to a CSV file\n",
    "def predict_and_write_results_ensemble(models, test_data_path, output_file_path):\n",
    "    # Load test data\n",
    "    test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "    # Impute missing values in test data\n",
    "    X_test_imputed = pd.DataFrame(imputer.transform(test_data), columns=test_data.columns)\n",
    "\n",
    "    # Make predictions using the ensemble of models\n",
    "    final_predictions = ensemble_predict(models, X_test_imputed)\n",
    "\n",
    "    # Create a DataFrame for results with ID and Predicted Category columns\n",
    "    results_df = pd.DataFrame({\n",
    "        'ID': np.arange(1, len(final_predictions) + 1),  # Assuming IDs start from 1\n",
    "        'Category': final_predictions\n",
    "    })\n",
    "\n",
    "    # Write the results to a CSV file\n",
    "    results_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Create sub-samples\n",
    "subsamples = create_subsamples(X_imputed, y)\n",
    "\n",
    "# Train random forest models on sub-samples\n",
    "random_forest_models = train_random_forest_models(subsamples)\n",
    "\n",
    "# Example usage:\n",
    "# Replace 'your_test_data.csv', 'output_results.csv' with your actual file paths\n",
    "predict_and_write_results_ensemble(random_forest_models, 'data/iith_foml_2023_test.csv', 'output_results.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
